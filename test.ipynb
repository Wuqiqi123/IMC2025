{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from mast3r.model import AsymmetricMASt3R\n",
    "from mast3r.fast_nn import fast_reciprocal_NNs\n",
    "import os\n",
    "import numpy as np\n",
    "import trimesh\n",
    "import copy\n",
    "from scipy.spatial.transform import Rotation\n",
    "import tempfile\n",
    "import shutil\n",
    "import torch\n",
    "import glob\n",
    "from mast3r.cloud_opt.sparse_ga import sparse_global_alignment\n",
    "from mast3r.cloud_opt.tsdf_optimizer import TSDFPostProcess\n",
    "from mast3r.image_pairs import make_pairs\n",
    "from mast3r.retrieval.processor import Retriever\n",
    "from mast3r.utils.misc import mkdir_for\n",
    "from cust3r.utils.image import load_images\n",
    "from dust3r.dust3r.utils.device import to_numpy\n",
    "from dust3r.dust3r.viz import add_scene_cam, CAM_COLORS, OPENGL, pts3d_to_trimesh, cat_meshes\n",
    "import matplotlib.pyplot as pl\n",
    "import imageio.v2 as iio\n",
    "import time\n",
    "from boq.boq_infer import get_trained_boq, boq_sort_topk\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _convert_scene_output_to_glb(imgs, pts3d, mask, focals, cams2world, cam_size=0.05,\n",
    "                                 cam_color=None, as_pointcloud=False,\n",
    "                                 transparent_cams=False, silent=False):\n",
    "    assert len(pts3d) == len(mask) <= len(imgs) <= len(cams2world) == len(focals)\n",
    "    pts3d = to_numpy(pts3d)\n",
    "    imgs = to_numpy(imgs)\n",
    "    focals = to_numpy(focals)\n",
    "    cams2world = to_numpy(cams2world)\n",
    "    scene = trimesh.Scene()\n",
    "    # full pointcloud\n",
    "    if as_pointcloud:\n",
    "        pts = np.concatenate([p[m.ravel()] for p, m in zip(pts3d, mask)]).reshape(-1, 3)\n",
    "        col = np.concatenate([p[m] for p, m in zip(imgs, mask)]).reshape(-1, 3)\n",
    "        valid_msk = np.isfinite(pts.sum(axis=1))\n",
    "        pct = trimesh.PointCloud(pts[valid_msk], colors=col[valid_msk])\n",
    "        scene.add_geometry(pct)\n",
    "    else:\n",
    "        meshes = []\n",
    "        for i in range(len(imgs)):\n",
    "            pts3d_i = pts3d[i].reshape(imgs[i].shape)\n",
    "            msk_i = mask[i] & np.isfinite(pts3d_i.sum(axis=-1))\n",
    "            meshes.append(pts3d_to_trimesh(imgs[i], pts3d_i, msk_i))\n",
    "        mesh = trimesh.Trimesh(**cat_meshes(meshes))\n",
    "        scene.add_geometry(mesh)\n",
    "    # add each camera\n",
    "    for i, pose_c2w in enumerate(cams2world):\n",
    "        if isinstance(cam_color, list):\n",
    "            camera_edge_color = cam_color[i]\n",
    "        else:\n",
    "            camera_edge_color = cam_color or CAM_COLORS[i % len(CAM_COLORS)]\n",
    "        add_scene_cam(scene, pose_c2w, camera_edge_color,\n",
    "                      None if transparent_cams else imgs[i], focals[i],\n",
    "                      imsize=imgs[i].shape[1::-1], screen_width=cam_size)\n",
    "    rot = np.eye(4)\n",
    "    rot[:3, :3] = Rotation.from_euler('y', np.deg2rad(180)).as_matrix()\n",
    "    scene.apply_transform(np.linalg.inv(cams2world[0] @ OPENGL @ rot))\n",
    "    return scene\n",
    "\n",
    "def get_3D_model_from_scene(silent, scene, min_conf_thr=2, as_pointcloud=False, mask_sky=False,\n",
    "                            clean_depth=False, transparent_cams=False, cam_size=0.05, TSDF_thresh=0):\n",
    "    \"\"\"\n",
    "    extract 3D_model (glb file) from a reconstructed scene\n",
    "    \"\"\"\n",
    "    # get optimized values from scene\n",
    "    scene = scene\n",
    "    rgbimg = scene.imgs\n",
    "    focals = scene.get_focals().cpu()\n",
    "    cams2world = scene.get_im_poses().cpu()\n",
    "    # 3D pointcloud from depthmap, poses and intrinsics\n",
    "    if TSDF_thresh > 0:\n",
    "        tsdf = TSDFPostProcess(scene, TSDF_thresh=TSDF_thresh)\n",
    "        pts3d, _, confs = to_numpy(tsdf.get_dense_pts3d(clean_depth=clean_depth))\n",
    "    else:\n",
    "        pts3d, _, confs = to_numpy(scene.get_dense_pts3d(clean_depth=clean_depth))\n",
    "    msk = to_numpy([c > min_conf_thr for c in confs])\n",
    "    return _convert_scene_output_to_glb(rgbimg, pts3d, msk, focals, cams2world, as_pointcloud=as_pointcloud,\n",
    "                                        transparent_cams=transparent_cams, cam_size=cam_size, silent=silent)\n",
    "    \n",
    "\n",
    "def get_reconstructed_scene(model, device, filelist,\n",
    "                            cache_path,\n",
    "                            retrieval_model = None,\n",
    "                            silent = False,\n",
    "                            optim_level = \"refine+depth\",\n",
    "                            lr1 = 0.07, niter1 = 200, lr2 = 0.01, niter2 = 200,\n",
    "                            min_conf_thr = 1.5,\n",
    "                            matching_conf_thr = 0.0,\n",
    "                            as_pointcloud = True, mask_sky = False, clean_depth =True, transparent_cams = False, cam_size = 0.2,\n",
    "                            scenegraph_type = \"complete\", winsize=1, win_cyclic=False, refid=0,\n",
    "                            TSDF_thresh=0.0, shared_intrinsics= False, half=False,\n",
    "                            **kw):\n",
    "    \"\"\"\n",
    "    from a list of images, run mast3r inference, sparse global aligner.\n",
    "    then run get_3D_model_from_scene\n",
    "    \"\"\"\n",
    "    imgs, imgs_id_dict = load_images(filelist, size=224, verbose=not silent)\n",
    "    if len(imgs) == 1:\n",
    "        imgs = [imgs[0], copy.deepcopy(imgs[0])]\n",
    "        imgs[1]['idx'] = 1\n",
    "        filelist = [filelist[0], filelist[0] + '_2']\n",
    "    scene_graph_params = [scenegraph_type]\n",
    "    if scenegraph_type in [\"swin\", \"logwin\"]:\n",
    "        scene_graph_params.append(str(winsize))\n",
    "    elif scenegraph_type == \"oneref\":\n",
    "        scene_graph_params.append(str(refid))\n",
    "    elif scenegraph_type == \"retrieval\":\n",
    "        scene_graph_params.append(str(winsize))  # Na\n",
    "        scene_graph_params.append(str(refid))  # k\n",
    "    if scenegraph_type in [\"swin\", \"logwin\"] and not win_cyclic:\n",
    "        scene_graph_params.append('noncyclic')\n",
    "    scene_graph = '-'.join(scene_graph_params)\n",
    "    sim_matrix = None\n",
    "    if 'retrieval' in scenegraph_type:\n",
    "        assert retrieval_model is not None\n",
    "        retriever = Retriever(retrieval_model, backbone=model, device=device)\n",
    "        with torch.no_grad():\n",
    "            sim_matrix = retriever(filelist)\n",
    "        # Cleanup\n",
    "        del retriever\n",
    "        torch.cuda.empty_cache()\n",
    "    boq_topks = None\n",
    "    if 'boq' in scenegraph_type:\n",
    "        with open(os.path.join(cache_path, \"boq_topk.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "            boq_topks = json.load(f)\n",
    "    pairs = make_pairs(imgs, scene_graph=scene_graph, prefilter=None, \n",
    "                       symmetrize=False, sim_mat=sim_matrix, boq_topk_dict=boq_topks, \n",
    "                       imgs_id_dict=imgs_id_dict)\n",
    "    if optim_level == 'coarse':\n",
    "        niter2 = 0\n",
    "    # Sparse GA (forward mast3r -> matching -> 3D optim -> 2D refinement -> triangulation)\n",
    "    scenes, outlier_imgs = sparse_global_alignment(filelist, imgs, imgs_id_dict, pairs, cache_path,\n",
    "                                    model, lr1=lr1, niter1=niter1, lr2=lr2, niter2=niter2, device=device,\n",
    "                                    opt_depth='depth' in optim_level, shared_intrinsics=shared_intrinsics,\n",
    "                                    matching_conf_thr=matching_conf_thr, half=half, **kw)\n",
    "    trimesh_scenes = []\n",
    "    for i, scene in enumerate(scenes):\n",
    "        trimesh_scene = get_3D_model_from_scene(silent, scene, min_conf_thr, as_pointcloud, mask_sky,\n",
    "                                      clean_depth, transparent_cams, cam_size, TSDF_thresh)\n",
    "        trimesh_scenes.append(trimesh_scene)\n",
    "    return trimesh_scenes, outlier_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'\n",
    "half = True\n",
    "model = AsymmetricMASt3R.from_pretrained(\"ckpts/MASt3R_ViTLarge_BaseDecoder_512_catmlpdpt_metric.pth\")\n",
    "if half:\n",
    "    model.half().to(device)\n",
    "else:\n",
    "    model.to(device)\n",
    "    \n",
    "image_list = []\n",
    "for filename in glob.glob('data/image-matching-challenge-2025/train/imc2023_haiper/*.png'): #assuming gif\n",
    "    image_list.append(filename)\n",
    "\n",
    "boq_model = get_trained_boq(backbone_name=\"dinov2\", output_dim=12288, ckpt='ckpts/dinov2_12288.pth')\n",
    "if half:\n",
    "    boq_model.half().to(device)\n",
    "else:\n",
    "    boq_model.to(device)\n",
    "    \n",
    "boq_model.eval()\n",
    "boq_topks = boq_sort_topk(image_list, boq_model, device, vis=False, topk=32, half=half)\n",
    "\n",
    "os.makedirs(\"outputs/imc2023_haiper\", exist_ok=True)\n",
    "with open(os.path.join(\"outputs/imc2023_haiper\", \"boq_topk.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(boq_topks, f, ensure_ascii=False, indent=4)\n",
    "    \n",
    "trimesh_scenes, outlier_imgs = get_reconstructed_scene(model, device, image_list, \"outputs/imc2023_haiper\", scenegraph_type = \"boq\", half=half)\n",
    "del model, boq_model\n",
    "torch.cuda.empty_cache()\n",
    "# trimesh_scenes[0].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trimesh_scenes[1].show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
