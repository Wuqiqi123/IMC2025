{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device=device(type='cuda', index=0)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from time import time, sleep\n",
    "import gc\n",
    "import numpy as np\n",
    "import h5py\n",
    "import dataclasses\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import kornia as K\n",
    "import kornia.feature as KF\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "from hloc import (\n",
    "    extract_features,\n",
    "    match_features,\n",
    "    reconstruction,\n",
    "    visualization,\n",
    "    pairs_from_exhaustive,\n",
    ")\n",
    "from hloc.visualization import plot_images, read_image\n",
    "from hloc.utils import viz_3d\n",
    "from transformers import AutoImageProcessor, AutoModel\n",
    "import pycolmap\n",
    "\n",
    "import metric\n",
    "\n",
    "\n",
    "device = K.utils.get_cuda_device_if_available(0)\n",
    "print(f'{device=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset \"imc2023_haiper\" -> num_images=54\n",
      "Dataset \"imc2023_heritage\" -> num_images=209\n",
      "Dataset \"imc2023_theather_imc2024_church\" -> num_images=76\n",
      "Dataset \"imc2024_dioscuri_baalshamin\" -> num_images=138\n",
      "Dataset \"imc2024_lizard_pond\" -> num_images=214\n",
      "Dataset \"pt_brandenburg_british_buckingham\" -> num_images=225\n",
      "Dataset \"pt_piazzasanmarco_grandplace\" -> num_images=168\n",
      "Dataset \"pt_sacrecoeur_trevi_tajmahal\" -> num_images=225\n",
      "Dataset \"pt_stpeters_stpauls\" -> num_images=200\n",
      "Dataset \"amy_gardens\" -> num_images=200\n",
      "Dataset \"fbk_vineyard\" -> num_images=163\n",
      "Dataset \"ETs\" -> num_images=22\n",
      "Dataset \"stairs\" -> num_images=51\n",
      "Skipping \"imc2023_haiper\"\n",
      "Skipping \"imc2023_heritage\"\n",
      "Skipping \"imc2023_theather_imc2024_church\"\n",
      "Skipping \"imc2024_dioscuri_baalshamin\"\n",
      "Skipping \"imc2024_lizard_pond\"\n",
      "Skipping \"pt_brandenburg_british_buckingham\"\n",
      "Skipping \"pt_piazzasanmarco_grandplace\"\n",
      "Skipping \"pt_sacrecoeur_trevi_tajmahal\"\n",
      "Skipping \"pt_stpeters_stpauls\"\n",
      "Skipping \"amy_gardens\"\n",
      "Skipping \"fbk_vineyard\"\n",
      "Images dir: data/image-matching-challenge-2025/train/ETs\n",
      "\n",
      "Processing dataset \"ETs\": 22 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025/05/05 14:17:23 hloc INFO] Extracting local features with configuration:\n",
      "{'model': {'max_keypoints': 5000, 'name': 'disk'},\n",
      " 'output': 'feats-disk',\n",
      " 'preprocessing': {'grayscale': False, 'resize_max': 1600}}\n",
      "100%|██████████| 22/22 [00:12<00:00,  1.72it/s]\n",
      "[2025/05/05 14:17:35 hloc INFO] Finished exporting features.\n",
      "[2025/05/05 14:17:35 hloc INFO] Found 231 pairs.\n",
      "[2025/05/05 14:17:35 hloc INFO] Matching local features with configuration:\n",
      "{'model': {'features': 'disk', 'name': 'lightglue'},\n",
      " 'output': 'matches-disk-lightglue'}\n",
      "100%|██████████| 231/231 [03:12<00:00,  1.20it/s]\n",
      "[2025/05/05 14:20:48 hloc INFO] Finished exporting matches.\n",
      "[2025/05/05 14:20:48 hloc INFO] Creating an empty database...\n",
      "[2025/05/05 14:20:48 hloc INFO] Importing images into the database...\n",
      "[2025/05/05 14:20:48 hloc INFO] Importing features into the database...\n",
      "100%|██████████| 22/22 [00:00<00:00, 1855.07it/s]\n",
      "[2025/05/05 14:20:48 hloc INFO] Importing matches into the database...\n",
      "100%|██████████| 231/231 [00:00<00:00, 1541.44it/s]\n",
      "[2025/05/05 14:20:48 hloc INFO] Performing geometric verification of the matches...\n",
      "I20250505 14:20:48.842518 129976653280832 misc.cc:44] \n",
      "==============================================================================\n",
      "Feature matching\n",
      "==============================================================================\n",
      "I20250505 14:20:48.842964 129976661673536 sift.cc:1432] Creating SIFT CPU feature matcher\n",
      "I20250505 14:20:48.842979 129976670066240 sift.cc:1432] Creating SIFT CPU feature matcher\n",
      "I20250505 14:20:48.843030 129981363516992 sift.cc:1432] Creating SIFT CPU feature matcher\n",
      "I20250505 14:20:48.843098 129981185115712 sift.cc:1432] Creating SIFT CPU feature matcher\n",
      "I20250505 14:20:48.843199 129976575718976 sift.cc:1432] Creating SIFT CPU feature matcher\n",
      "I20250505 14:20:48.843233 129976531678784 sift.cc:1432] Creating SIFT CPU feature matcher\n",
      "I20250505 14:20:48.843272 129976487638592 sift.cc:1432] Creating SIFT CPU feature matcher\n",
      "I20250505 14:20:48.843302 129976443598400 sift.cc:1432] Creating SIFT CPU feature matcher\n",
      "I20250505 14:20:48.843361 129976399558208 sift.cc:1432] Creating SIFT CPU feature matcher\n",
      "I20250505 14:20:48.843505 129974568756800 sift.cc:1432] Creating SIFT CPU feature matcher\n",
      "I20250505 14:20:48.843516 129974434526784 sift.cc:1432] Creating SIFT CPU feature matcher\n",
      "I20250505 14:20:48.843532 129974560364096 sift.cc:1432] Creating SIFT CPU feature matcher\n",
      "I20250505 14:20:48.843688 129974551971392 sift.cc:1432] Creating SIFT CPU feature matcher\n",
      "I20250505 14:20:48.843716 129974543578688 sift.cc:1432] Creating SIFT CPU feature matcher\n",
      "I20250505 14:20:48.843758 129974535185984 sift.cc:1432] Creating SIFT CPU feature matcher\n",
      "I20250505 14:20:48.843831 129974526793280 sift.cc:1432] Creating SIFT CPU feature matcher\n",
      "I20250505 14:20:48.844237 129976653280832 pairing.cc:742] Importing image pairs...\n",
      "I20250505 14:20:48.844448 129976653280832 pairing.cc:775] Matching block [1/1]\n",
      "I20250505 14:20:48.975141 129976653280832 feature_matching.cc:46] in 0.131s\n",
      "I20250505 14:20:48.976750 129976653280832 timer.cc:91] Elapsed time: 0.002 [minutes]\n",
      "[2025/05/05 14:20:48 hloc INFO] Running 3D reconstruction...\n",
      "I20250505 14:20:48.984809 129982275424704 incremental_pipeline.cc:237] Loading database\n",
      "I20250505 14:20:48.985806 129982275424704 database_cache.cc:66] Loading cameras...\n",
      "I20250505 14:20:48.985845 129982275424704 database_cache.cc:76]  22 in 0.000s\n",
      "I20250505 14:20:48.985854 129982275424704 database_cache.cc:84] Loading matches...\n",
      "I20250505 14:20:48.986387 129982275424704 database_cache.cc:89]  82 in 0.001s\n",
      "I20250505 14:20:48.986398 129982275424704 database_cache.cc:105] Loading images...\n",
      "I20250505 14:20:48.987466 129982275424704 database_cache.cc:153]  22 in 0.001s (connected 19)\n",
      "I20250505 14:20:48.987484 129982275424704 database_cache.cc:164] Loading pose priors...\n",
      "I20250505 14:20:48.987560 129982275424704 database_cache.cc:175]  0 in 0.000s\n",
      "I20250505 14:20:48.987564 129982275424704 database_cache.cc:184] Building correspondence graph...\n",
      "I20250505 14:20:48.992903 129982275424704 database_cache.cc:210]  in 0.005s (ignored 0)\n",
      "I20250505 14:20:48.992955 129982275424704 timer.cc:91] Elapsed time: 0.000 [minutes]\n",
      "I20250505 14:20:48.993807 129982275424704 incremental_pipeline.cc:282] Finding good initial image pair\n",
      "I20250505 14:20:49.113902 129982275424704 incremental_pipeline.cc:306] Initializing with image pair #11 and #15\n",
      "I20250505 14:20:49.116779 129982275424704 incremental_pipeline.cc:311] Global bundle adjustment\n",
      "I20250505 14:20:49.449628 129982275424704 incremental_pipeline.cc:390] Registering image #14 (3)\n",
      "I20250505 14:20:49.449657 129982275424704 incremental_pipeline.cc:393] => Image sees 708 / 2247 points\n",
      "I20250505 14:20:49.797290 129982275424704 incremental_pipeline.cc:42] Retriangulation and Global bundle adjustment\n",
      "I20250505 14:20:49.871357 129982275424704 incremental_pipeline.cc:390] Registering image #12 (4)\n",
      "I20250505 14:20:49.871386 129982275424704 incremental_pipeline.cc:393] => Image sees 1163 / 2334 points\n",
      "I20250505 14:20:50.201567 129982275424704 incremental_pipeline.cc:42] Retriangulation and Global bundle adjustment\n",
      "I20250505 14:20:50.315047 129982275424704 incremental_pipeline.cc:390] Registering image #13 (5)\n",
      "I20250505 14:20:50.315077 129982275424704 incremental_pipeline.cc:393] => Image sees 1446 / 2024 points\n",
      "I20250505 14:20:50.581117 129982275424704 incremental_pipeline.cc:42] Retriangulation and Global bundle adjustment\n",
      "I20250505 14:20:50.725198 129982275424704 incremental_pipeline.cc:390] Registering image #17 (6)\n",
      "I20250505 14:20:50.725258 129982275424704 incremental_pipeline.cc:393] => Image sees 488 / 2185 points\n",
      "I20250505 14:20:50.979099 129982275424704 incremental_pipeline.cc:42] Retriangulation and Global bundle adjustment\n",
      "I20250505 14:20:51.133258 129982275424704 incremental_pipeline.cc:390] Registering image #16 (7)\n",
      "I20250505 14:20:51.133287 129982275424704 incremental_pipeline.cc:393] => Image sees 531 / 2061 points\n",
      "I20250505 14:20:51.539231 129982275424704 incremental_pipeline.cc:42] Retriangulation and Global bundle adjustment\n",
      "I20250505 14:20:51.744892 129982275424704 incremental_pipeline.cc:390] Registering image #18 (8)\n",
      "I20250505 14:20:51.744921 129982275424704 incremental_pipeline.cc:393] => Image sees 1445 / 2114 points\n",
      "I20250505 14:20:52.066715 129982275424704 incremental_pipeline.cc:42] Retriangulation and Global bundle adjustment\n",
      "I20250505 14:20:52.305502 129982275424704 incremental_pipeline.cc:390] Registering image #19 (9)\n",
      "I20250505 14:20:52.305526 129982275424704 incremental_pipeline.cc:393] => Image sees 1244 / 1568 points\n",
      "I20250505 14:20:52.612356 129982275424704 incremental_pipeline.cc:42] Retriangulation and Global bundle adjustment\n",
      "I20250505 14:20:52.885280 129982275424704 incremental_pipeline.cc:390] Registering image #3 (10)\n",
      "I20250505 14:20:52.885305 129982275424704 incremental_pipeline.cc:393] => Image sees 31 / 1330 points\n",
      "I20250505 14:20:52.886090 129982275424704 incremental_pipeline.cc:404] => Could not register, trying another image.\n",
      "I20250505 14:20:52.886094 129982275424704 incremental_pipeline.cc:390] Registering image #2 (10)\n",
      "I20250505 14:20:52.886097 129982275424704 incremental_pipeline.cc:393] => Image sees 31 / 1780 points\n",
      "I20250505 14:20:52.887233 129982275424704 incremental_pipeline.cc:404] => Could not register, trying another image.\n",
      "I20250505 14:20:52.887237 129982275424704 incremental_pipeline.cc:42] Retriangulation and Global bundle adjustment\n",
      "I20250505 14:20:53.113850 129982275424704 incremental_pipeline.cc:390] Registering image #3 (10)\n",
      "I20250505 14:20:53.113887 129982275424704 incremental_pipeline.cc:393] => Image sees 31 / 1330 points\n",
      "I20250505 14:20:53.114336 129982275424704 incremental_pipeline.cc:404] => Could not register, trying another image.\n",
      "I20250505 14:20:53.114340 129982275424704 incremental_pipeline.cc:390] Registering image #2 (10)\n",
      "I20250505 14:20:53.114343 129982275424704 incremental_pipeline.cc:393] => Image sees 31 / 1780 points\n",
      "I20250505 14:20:53.115826 129982275424704 incremental_pipeline.cc:404] => Could not register, trying another image.\n",
      "I20250505 14:20:53.116514 129982275424704 incremental_pipeline.cc:282] Finding good initial image pair\n",
      "I20250505 14:20:53.164684 129982275424704 incremental_pipeline.cc:306] Initializing with image pair #1 and #3\n",
      "I20250505 14:20:53.165844 129982275424704 incremental_pipeline.cc:311] Global bundle adjustment\n",
      "I20250505 14:20:53.202867 129982275424704 incremental_pipeline.cc:390] Registering image #4 (3)\n",
      "I20250505 14:20:53.202889 129982275424704 incremental_pipeline.cc:393] => Image sees 84 / 1629 points\n",
      "I20250505 14:20:53.284967 129982275424704 incremental_pipeline.cc:42] Retriangulation and Global bundle adjustment\n",
      "I20250505 14:20:54.158996 129982275424704 incremental_pipeline.cc:390] Registering image #2 (4)\n",
      "I20250505 14:20:54.159022 129982275424704 incremental_pipeline.cc:393] => Image sees 413 / 1780 points\n",
      "I20250505 14:20:54.393761 129982275424704 incremental_pipeline.cc:42] Retriangulation and Global bundle adjustment\n",
      "I20250505 14:20:54.780960 129982275424704 incremental_pipeline.cc:390] Registering image #5 (5)\n",
      "I20250505 14:20:54.780984 129982275424704 incremental_pipeline.cc:393] => Image sees 853 / 1525 points\n",
      "I20250505 14:20:55.040619 129982275424704 incremental_pipeline.cc:42] Retriangulation and Global bundle adjustment\n",
      "I20250505 14:20:55.227905 129982275424704 incremental_pipeline.cc:390] Registering image #6 (6)\n",
      "I20250505 14:20:55.227925 129982275424704 incremental_pipeline.cc:393] => Image sees 805 / 1271 points\n",
      "I20250505 14:20:55.450856 129982275424704 incremental_pipeline.cc:42] Retriangulation and Global bundle adjustment\n",
      "I20250505 14:20:55.631656 129982275424704 incremental_pipeline.cc:390] Registering image #7 (7)\n",
      "I20250505 14:20:55.631694 129982275424704 incremental_pipeline.cc:393] => Image sees 590 / 1195 points\n",
      "I20250505 14:20:55.864480 129982275424704 incremental_pipeline.cc:42] Retriangulation and Global bundle adjustment\n",
      "I20250505 14:20:56.175543 129982275424704 incremental_pipeline.cc:390] Registering image #8 (8)\n",
      "I20250505 14:20:56.175568 129982275424704 incremental_pipeline.cc:393] => Image sees 415 / 1115 points\n",
      "I20250505 14:20:56.326242 129982275424704 incremental_pipeline.cc:42] Retriangulation and Global bundle adjustment\n",
      "I20250505 14:20:56.519401 129982275424704 incremental_pipeline.cc:390] Registering image #9 (9)\n",
      "I20250505 14:20:56.519423 129982275424704 incremental_pipeline.cc:393] => Image sees 347 / 750 points\n",
      "I20250505 14:20:56.632826 129982275424704 incremental_pipeline.cc:42] Retriangulation and Global bundle adjustment\n",
      "I20250505 14:20:56.832599 129982275424704 incremental_pipeline.cc:390] Registering image #10 (10)\n",
      "I20250505 14:20:56.832621 129982275424704 incremental_pipeline.cc:393] => Image sees 280 / 523 points\n",
      "I20250505 14:20:56.930072 129982275424704 incremental_pipeline.cc:42] Retriangulation and Global bundle adjustment\n",
      "I20250505 14:20:57.095242 129982275424704 incremental_pipeline.cc:390] Registering image #17 (11)\n",
      "I20250505 14:20:57.095263 129982275424704 incremental_pipeline.cc:393] => Image sees 44 / 2185 points\n",
      "I20250505 14:20:57.097006 129982275424704 incremental_pipeline.cc:404] => Could not register, trying another image.\n",
      "I20250505 14:20:57.097010 129982275424704 incremental_pipeline.cc:390] Registering image #18 (11)\n",
      "I20250505 14:20:57.097014 129982275424704 incremental_pipeline.cc:393] => Image sees 41 / 2114 points\n",
      "I20250505 14:20:57.098355 129982275424704 incremental_pipeline.cc:404] => Could not register, trying another image.\n",
      "I20250505 14:20:57.098359 129982275424704 incremental_pipeline.cc:42] Retriangulation and Global bundle adjustment\n",
      "I20250505 14:20:57.129319 129982275424704 incremental_pipeline.cc:390] Registering image #17 (11)\n",
      "I20250505 14:20:57.129345 129982275424704 incremental_pipeline.cc:393] => Image sees 44 / 2185 points\n",
      "I20250505 14:20:57.130841 129982275424704 incremental_pipeline.cc:404] => Could not register, trying another image.\n",
      "I20250505 14:20:57.130845 129982275424704 incremental_pipeline.cc:390] Registering image #18 (11)\n",
      "I20250505 14:20:57.130848 129982275424704 incremental_pipeline.cc:393] => Image sees 41 / 2114 points\n",
      "I20250505 14:20:57.132934 129982275424704 incremental_pipeline.cc:404] => Could not register, trying another image.\n",
      "I20250505 14:20:57.133094 129982275424704 timer.cc:91] Elapsed time: 0.136 [minutes]\n",
      "[2025/05/05 14:20:57 hloc INFO] Reconstructed 2 model(s).\n",
      "[2025/05/05 14:20:57 hloc INFO] Largest model is #1 with 10 images.\n",
      "[2025/05/05 14:20:57 hloc INFO] Reconstruction statistics:\n",
      "Reconstruction:\n",
      "\tnum_cameras = 10\n",
      "\tnum_images = 10\n",
      "\tnum_reg_images = 10\n",
      "\tnum_points3D = 2095\n",
      "\tnum_observations = 9308\n",
      "\tmean_track_length = 4.44296\n",
      "\tmean_observations_per_image = 930.8\n",
      "\tmean_reprojection_error = 0.876041\n",
      "\tnum_input_images = 22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset \"ETs\" -> Registered 19 / 22 images with 2 clusters\n",
      "Images dir: data/image-matching-challenge-2025/train/stairs\n",
      "\n",
      "Processing dataset \"stairs\": 51 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025/05/05 14:20:58 hloc INFO] Extracting local features with configuration:\n",
      "{'model': {'max_keypoints': 5000, 'name': 'disk'},\n",
      " 'output': 'feats-disk',\n",
      " 'preprocessing': {'grayscale': False, 'resize_max': 1600}}\n",
      "100%|██████████| 51/51 [02:21<00:00,  2.77s/it]\n",
      "[2025/05/05 14:23:19 hloc INFO] Finished exporting features.\n",
      "[2025/05/05 14:23:19 hloc INFO] Found 1275 pairs.\n",
      "[2025/05/05 14:23:19 hloc INFO] Matching local features with configuration:\n",
      "{'model': {'features': 'disk', 'name': 'lightglue'},\n",
      " 'output': 'matches-disk-lightglue'}\n",
      "  0%|          | 0/1275 [00:00<?, ?it/s]ERROR: Unexpected bus error encountered in worker. This might be caused by insufficient shared memory (shm).\n",
      "  0%|          | 4/1275 [00:17<1:30:56,  4.29s/it]"
     ]
    }
   ],
   "source": [
    "def load_torch_image(fname, device=torch.device('cpu')):\n",
    "    img = K.io.load_image(fname, K.io.ImageLoadType.RGB32, device=device)[None, ...]\n",
    "    return img\n",
    "\n",
    "\n",
    "# Must Use efficientnet global descriptor to get matching shortlists.\n",
    "def get_global_desc(fnames, device = torch.device('cpu')):\n",
    "    processor = AutoImageProcessor.from_pretrained('facebook/dinov2-base')\n",
    "    model = AutoModel.from_pretrained('facebook/dinov2-base')\n",
    "    model = model.eval()\n",
    "    model = model.to(device)\n",
    "    global_descs_dinov2 = []\n",
    "    for i, img_fname_full in tqdm(enumerate(fnames),total= len(fnames)):\n",
    "        key = os.path.splitext(os.path.basename(img_fname_full))[0]\n",
    "        timg = load_torch_image(img_fname_full)\n",
    "        with torch.inference_mode():\n",
    "            inputs = processor(images=timg, return_tensors=\"pt\", do_rescale=False).to(device)\n",
    "            outputs = model(**inputs)\n",
    "            dino_mac = F.normalize(outputs.last_hidden_state[:,1:].max(dim=1)[0], dim=1, p=2)\n",
    "        global_descs_dinov2.append(dino_mac.detach().cpu())\n",
    "    global_descs_dinov2 = torch.cat(global_descs_dinov2, dim=0)\n",
    "    return global_descs_dinov2\n",
    "\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class Prediction:\n",
    "    image_id: str | None  # A unique identifier for the row -- unused otherwise. Used only on the hidden test set.\n",
    "    dataset: str\n",
    "    filename: str\n",
    "    cluster_index: int | None = None\n",
    "    rotation: np.ndarray | None = None\n",
    "    translation: np.ndarray | None = None\n",
    "\n",
    "# Set is_train=True to run the notebook on the training data.\n",
    "# Set is_train=False if submitting an entry to the competition (test data is hidden, and different from what you see on the \"test\" folder).\n",
    "is_train = True\n",
    "data_dir = 'data/image-matching-challenge-2025'\n",
    "workdir = 'result/'\n",
    "os.makedirs(workdir, exist_ok=True)\n",
    "workdir = Path(workdir)\n",
    "\n",
    "if is_train:\n",
    "    sample_submission_csv = os.path.join(data_dir, 'train_labels.csv')\n",
    "else:\n",
    "    sample_submission_csv = os.path.join(data_dir, 'sample_submission.csv')\n",
    "\n",
    "samples = {}\n",
    "competition_data = pd.read_csv(sample_submission_csv)\n",
    "for _, row in competition_data.iterrows():\n",
    "    # Note: For the test data, the \"scene\" column has no meaning, and the rotation_matrix and translation_vector columns are random.\n",
    "    if row.dataset not in samples:\n",
    "        samples[row.dataset] = []\n",
    "    samples[row.dataset].append(\n",
    "        Prediction(\n",
    "            image_id=None if is_train else row.image_id,\n",
    "            dataset=row.dataset,\n",
    "            filename=row.image\n",
    "        )\n",
    "    )\n",
    "\n",
    "for dataset in samples:\n",
    "    print(f'Dataset \"{dataset}\" -> num_images={len(samples[dataset])}')\n",
    "\n",
    "max_images = None  # Used For debugging only. Set to None to disable.\n",
    "datasets_to_process = None  # Not the best convention, but None means all datasets.\n",
    "\n",
    "if is_train:\n",
    "    # max_images = 5\n",
    "\n",
    "    # Note: When running on the training dataset, the notebook will hit the time limit and die. Use this filter to run on a few specific datasets.\n",
    "    datasets_to_process = [\n",
    "    \t# New data.\n",
    "    \t# 'amy_gardens',\n",
    "    \t'ETs',\n",
    "    \t# 'fbk_vineyard',\n",
    "    \t'stairs',\n",
    "    \t# Data from IMC 2023 and 2024.\n",
    "    \t# 'imc2024_dioscuri_baalshamin',\n",
    "    \t# 'imc2023_theather_imc2024_church',\n",
    "    \t# 'imc2023_heritage',\n",
    "    \t# 'imc2023_haiper',\n",
    "    \t# 'imc2024_lizard_pond',\n",
    "    \t# Crowdsourced PhotoTourism data.\n",
    "    \t# 'pt_stpeters_stpauls',\n",
    "    \t# 'pt_brandenburg_british_buckingham',\n",
    "    \t# 'pt_piazzasanmarco_grandplace',\n",
    "    \t# 'pt_sacrecoeur_trevi_tajmahal',\n",
    "    ]\n",
    "\n",
    "for dataset, predictions in samples.items():\n",
    "    if datasets_to_process and dataset not in datasets_to_process:\n",
    "        print(f'Skipping \"{dataset}\"')\n",
    "        continue\n",
    "    \n",
    "    images_dir = os.path.join(data_dir, 'train' if is_train else 'test', dataset)\n",
    "    if not os.path.exists(images_dir):\n",
    "        print(f'Images dir \"{images_dir}\" does not exist. Skipping \"{dataset}\"')\n",
    "        continue\n",
    "    \n",
    "    images_dir = Path(images_dir)\n",
    "\n",
    "    print(f'Images dir: {images_dir}')\n",
    "\n",
    "    image_names = [p.filename for p in predictions]\n",
    "    if max_images is not None:\n",
    "        image_names = image_names[:max_images]\n",
    "\n",
    "    print(f'\\nProcessing dataset \"{dataset}\": {len(image_names)} images')\n",
    "\n",
    "    filename_to_index = {p.filename: idx for idx, p in enumerate(predictions)}\n",
    "    \n",
    "    !rm -rf $workdir/$dataset\n",
    "\n",
    "    sfm_pairs = workdir / dataset / \"pairs-sfm.txt\"\n",
    "    loc_pairs = workdir / dataset / \"pairs-loc.txt\"\n",
    "    sfm_dir = workdir / dataset / \"sfm\"\n",
    "    features = workdir / dataset / \"features.h5\"\n",
    "    matches = workdir / dataset / \"matches.h5\"\n",
    "\n",
    "    feature_conf = extract_features.confs[\"disk\"]\n",
    "    matcher_conf = match_features.confs[\"disk+lightglue\"]\n",
    "\n",
    "    extract_features.main(feature_conf, images_dir, image_list=image_names, feature_path=features)\n",
    "    pairs_from_exhaustive.main(sfm_pairs, image_list=image_names)\n",
    "    match_features.main(matcher_conf, sfm_pairs, features=features, matches=matches)\n",
    "    \n",
    "    # # By default colmap does not generate a reconstruction if less than 10 images are registered.\n",
    "    # # Lower it to 3.\n",
    "    mapper_options = {\"min_model_size\" : 3, \"max_num_models\": 25}\n",
    "    max_map, maps = reconstruction.main(\n",
    "        sfm_dir, images_dir, sfm_pairs, features, matches,\n",
    "        image_list=image_names, min_match_score=0.2, mapper_options = mapper_options, \n",
    "    )\n",
    "    gc.collect()\n",
    "    sleep(1)\n",
    "\n",
    "    registered = 0\n",
    "    for map_index, cur_map in maps.items():\n",
    "        for index, image in cur_map.images.items():\n",
    "            prediction_index = filename_to_index[image.name]\n",
    "            predictions[prediction_index].cluster_index = map_index\n",
    "            predictions[prediction_index].rotation = deepcopy(image.cam_from_world.rotation.matrix())\n",
    "            predictions[prediction_index].translation = deepcopy(image.cam_from_world.translation)\n",
    "            registered += 1\n",
    "    mapping_result_str = f'Dataset \"{dataset}\" -> Registered {registered} / {len(image_names)} images with {len(maps)} clusters'\n",
    "    print(mapping_result_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset,scene,image,rotation_matrix,translation_vector\n",
      "imc2023_haiper,outliers,fountain_image_116.png,nan;nan;nan;nan;nan;nan;nan;nan;nan,nan;nan;nan\n",
      "imc2023_haiper,outliers,fountain_image_108.png,nan;nan;nan;nan;nan;nan;nan;nan;nan,nan;nan;nan\n",
      "imc2023_haiper,outliers,fountain_image_101.png,nan;nan;nan;nan;nan;nan;nan;nan;nan,nan;nan;nan\n",
      "imc2023_haiper,outliers,fountain_image_082.png,nan;nan;nan;nan;nan;nan;nan;nan;nan,nan;nan;nan\n",
      "imc2023_haiper,outliers,fountain_image_071.png,nan;nan;nan;nan;nan;nan;nan;nan;nan,nan;nan;nan\n",
      "imc2023_haiper,outliers,fountain_image_025.png,nan;nan;nan;nan;nan;nan;nan;nan;nan,nan;nan;nan\n",
      "imc2023_haiper,outliers,fountain_image_000.png,nan;nan;nan;nan;nan;nan;nan;nan;nan,nan;nan;nan\n",
      "imc2023_haiper,outliers,fountain_image_007.png,nan;nan;nan;nan;nan;nan;nan;nan;nan,nan;nan;nan\n",
      "imc2023_haiper,outliers,fountain_image_012.png,nan;nan;nan;nan;nan;nan;nan;nan;nan,nan;nan;nan\n"
     ]
    }
   ],
   "source": [
    "# Must Create a submission file.\n",
    "\n",
    "array_to_str = lambda array: ';'.join([f\"{x:.09f}\" for x in array])\n",
    "none_to_str = lambda n: ';'.join(['nan'] * n)\n",
    "\n",
    "submission_file = 'result/submission.csv'\n",
    "with open(submission_file, 'w') as f:\n",
    "    if is_train:\n",
    "        f.write('dataset,scene,image,rotation_matrix,translation_vector\\n')\n",
    "        for dataset in samples:\n",
    "            for prediction in samples[dataset]:\n",
    "                cluster_name = 'outliers' if prediction.cluster_index is None else f'cluster{prediction.cluster_index}'\n",
    "                rotation = none_to_str(9) if prediction.rotation is None else array_to_str(prediction.rotation.flatten())\n",
    "                translation = none_to_str(3) if prediction.translation is None else array_to_str(prediction.translation)\n",
    "                f.write(f'{prediction.dataset},{cluster_name},{prediction.filename},{rotation},{translation}\\n')\n",
    "    else:\n",
    "        f.write('image_id,dataset,scene,image,rotation_matrix,translation_vector\\n')\n",
    "        for dataset in samples:\n",
    "            for prediction in samples[dataset]:\n",
    "                cluster_name = 'outliers' if prediction.cluster_index is None else f'cluster{prediction.cluster_index}'\n",
    "                rotation = none_to_str(9) if prediction.rotation is None else array_to_str(prediction.rotation.flatten())\n",
    "                translation = none_to_str(3) if prediction.translation is None else array_to_str(prediction.translation)\n",
    "                f.write(f'{prediction.image_id},{prediction.dataset},{cluster_name},{prediction.filename},{rotation},{translation}\\n')\n",
    "\n",
    "!head {submission_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imc2023_haiper: score=0.00% (mAA=0.00%, clusterness=0.00%)\n",
      "imc2023_heritage: score=0.00% (mAA=0.00%, clusterness=0.00%)\n",
      "imc2023_theather_imc2024_church: score=0.00% (mAA=0.00%, clusterness=0.00%)\n",
      "imc2024_dioscuri_baalshamin: score=0.00% (mAA=0.00%, clusterness=0.00%)\n",
      "imc2024_lizard_pond: score=0.00% (mAA=0.00%, clusterness=0.00%)\n",
      "pt_brandenburg_british_buckingham: score=0.00% (mAA=0.00%, clusterness=0.00%)\n",
      "pt_piazzasanmarco_grandplace: score=0.00% (mAA=0.00%, clusterness=0.00%)\n",
      "pt_sacrecoeur_trevi_tajmahal: score=0.00% (mAA=0.00%, clusterness=0.00%)\n",
      "pt_stpeters_stpauls: score=0.00% (mAA=0.00%, clusterness=0.00%)\n",
      "amy_gardens: score=0.00% (mAA=0.00%, clusterness=0.00%)\n",
      "fbk_vineyard: score=0.00% (mAA=0.00%, clusterness=0.00%)\n",
      "ETs: score=51.43% (mAA=34.62%, clusterness=100.00%)\n",
      "stairs: score=0.00% (mAA=0.00%, clusterness=50.00%)\n",
      "Average over all datasets: score=3.96% (mAA=2.66%, clusterness=11.54%)\n",
      "Computed metric in: 0.43 sec.\n"
     ]
    }
   ],
   "source": [
    "# Definitely Compute results if running on the training set.\n",
    "# Do not do this when submitting a notebook for scoring. All you have to do is save your submission to /kaggle/working/submission.csv.\n",
    "\n",
    "if is_train:\n",
    "    t = time()\n",
    "    final_score, dataset_scores = metric.score(\n",
    "        gt_csv='data/image-matching-challenge-2025/train_labels.csv',\n",
    "        user_csv=submission_file,\n",
    "        thresholds_csv='data/image-matching-challenge-2025/train_thresholds.csv',\n",
    "        mask_csv=None if is_train else os.path.join(data_dir, 'mask.csv'),\n",
    "        inl_cf=0,\n",
    "        strict_cf=-1,\n",
    "        verbose=True,\n",
    "    )\n",
    "    print(f'Computed metric in: {time() - t:.02f} sec.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
