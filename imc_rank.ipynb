{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device=device(type='cuda', index=0)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from time import time, sleep\n",
    "import gc\n",
    "import numpy as np\n",
    "import h5py\n",
    "import dataclasses\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import kornia as K\n",
    "import kornia.feature as KF\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "from hloc import (\n",
    "    extract_features,\n",
    "    match_features,\n",
    "    reconstruction,\n",
    "    visualization,\n",
    "    pairs_from_exhaustive,\n",
    ")\n",
    "from hloc.visualization import plot_images, read_image\n",
    "from hloc.utils import viz_3d\n",
    "from transformers import AutoImageProcessor, AutoModel\n",
    "import pycolmap\n",
    "\n",
    "import metric\n",
    "import time\n",
    "import json\n",
    "from boq_inferface import boq_sort_topk\n",
    "from boq_inferface import get_trained_boq\n",
    "\n",
    "\n",
    "device = K.utils.get_cuda_device_if_available(0)\n",
    "print(f'{device=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "/root/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is not available (SwiGLU)\")\n",
      "/root/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:33: UserWarning: xFormers is not available (Attention)\n",
      "  warnings.warn(\"xFormers is not available (Attention)\")\n",
      "/root/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:40: UserWarning: xFormers is not available (Block)\n",
      "  warnings.warn(\"xFormers is not available (Block)\")\n",
      "INFO:dinov2:using MLP layer as FFN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VPRModel(\n",
       "  (backbone): DinoV2(\n",
       "    (dino): DinoVisionTransformer(\n",
       "      (patch_embed): PatchEmbed(\n",
       "        (proj): Conv2d(3, 768, kernel_size=(14, 14), stride=(14, 14))\n",
       "        (norm): Identity()\n",
       "      )\n",
       "      (blocks): ModuleList(\n",
       "        (0-11): 12 x NestedTensorBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): MemEffAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (head): Identity()\n",
       "    )\n",
       "  )\n",
       "  (aggregator): BoQ(\n",
       "    (proj_c): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (norm_input): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    (boqs): ModuleList(\n",
       "      (0-1): 2 x BoQBlock(\n",
       "        (encoder): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (linear2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.0, inplace=False)\n",
       "          (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n",
       "        )\n",
       "        (norm_q): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (cross_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n",
       "        )\n",
       "        (norm_out): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (fc): Linear(in_features=128, out_features=32, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda:0'\n",
    "boq_model = get_trained_boq(backbone_name=\"dinov2\", output_dim=12288)\n",
    "boq_model.to(device)\n",
    "boq_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset \"imc2023_haiper\" -> num_images=54\n",
      "Dataset \"imc2023_heritage\" -> num_images=209\n",
      "Dataset \"imc2023_theather_imc2024_church\" -> num_images=76\n",
      "Dataset \"imc2024_dioscuri_baalshamin\" -> num_images=138\n",
      "Dataset \"imc2024_lizard_pond\" -> num_images=214\n",
      "Dataset \"pt_brandenburg_british_buckingham\" -> num_images=225\n",
      "Dataset \"pt_piazzasanmarco_grandplace\" -> num_images=168\n",
      "Dataset \"pt_sacrecoeur_trevi_tajmahal\" -> num_images=225\n",
      "Dataset \"pt_stpeters_stpauls\" -> num_images=200\n",
      "Dataset \"amy_gardens\" -> num_images=200\n",
      "Dataset \"fbk_vineyard\" -> num_images=163\n",
      "Dataset \"ETs\" -> num_images=22\n",
      "Dataset \"stairs\" -> num_images=51\n",
      "Images dir: data/image-matching-challenge-2025/train/imc2023_haiper\n",
      "\n",
      "Processing dataset \"imc2023_haiper\": 54 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025/05/09 16:31:33 hloc INFO] Extracting local features with configuration:\n",
      "{'model': {'max_keypoints': 5000, 'name': 'disk'},\n",
      " 'output': 'feats-disk',\n",
      " 'preprocessing': {'grayscale': False, 'resize_max': 1600}}\n",
      "100%|██████████| 54/54 [00:13<00:00,  3.91it/s]\n",
      "[2025/05/09 16:31:47 hloc INFO] Finished exporting features.\n",
      "[2025/05/09 16:31:47 hloc INFO] Found 1431 pairs.\n",
      "[2025/05/09 16:31:47 hloc INFO] Matching local features with configuration:\n",
      "{'model': {'features': 'disk', 'name': 'lightglue'},\n",
      " 'output': 'matches-disk-lightglue'}\n",
      "100%|██████████| 1431/1431 [01:31<00:00, 15.66it/s]\n",
      "[2025/05/09 16:33:19 hloc INFO] Finished exporting matches.\n",
      "100%|██████████| 1431/1431 [00:07<00:00, 185.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93BOQ TOPK time: 288.11527037620544 seconds\u001b[0m\n",
      "Images dir: data/image-matching-challenge-2025/train/imc2023_heritage\n",
      "\n",
      "Processing dataset \"imc2023_heritage\": 209 images\n"
     ]
    }
   ],
   "source": [
    "def load_torch_image(fname, device=torch.device('cpu')):\n",
    "    img = K.io.load_image(fname, K.io.ImageLoadType.RGB32, device=device)[None, ...]\n",
    "    return img\n",
    "\n",
    "\n",
    "# Must Use efficientnet global descriptor to get matching shortlists.\n",
    "def get_global_desc(fnames, device = torch.device('cpu')):\n",
    "    processor = AutoImageProcessor.from_pretrained('facebook/dinov2-base')\n",
    "    model = AutoModel.from_pretrained('facebook/dinov2-base')\n",
    "    model = model.eval()\n",
    "    model = model.to(device)\n",
    "    global_descs_dinov2 = []\n",
    "    for i, img_fname_full in tqdm(enumerate(fnames),total= len(fnames)):\n",
    "        key = os.path.splitext(os.path.basename(img_fname_full))[0]\n",
    "        timg = load_torch_image(img_fname_full)\n",
    "        with torch.inference_mode():\n",
    "            inputs = processor(images=timg, return_tensors=\"pt\", do_rescale=False).to(device)\n",
    "            outputs = model(**inputs)\n",
    "            dino_mac = F.normalize(outputs.last_hidden_state[:,1:].max(dim=1)[0], dim=1, p=2)\n",
    "        global_descs_dinov2.append(dino_mac.detach().cpu())\n",
    "    global_descs_dinov2 = torch.cat(global_descs_dinov2, dim=0)\n",
    "    return global_descs_dinov2\n",
    "\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class Prediction:\n",
    "    image_id: str | None  # A unique identifier for the row -- unused otherwise. Used only on the hidden test set.\n",
    "    dataset: str\n",
    "    filename: str\n",
    "    cluster_index: int | None = None\n",
    "    rotation: np.ndarray | None = None\n",
    "    translation: np.ndarray | None = None\n",
    "\n",
    "# Set is_train=True to run the notebook on the training data.\n",
    "# Set is_train=False if submitting an entry to the competition (test data is hidden, and different from what you see on the \"test\" folder).\n",
    "is_train = True\n",
    "data_dir = 'data/image-matching-challenge-2025'\n",
    "workdir = 'result/'\n",
    "os.makedirs(workdir, exist_ok=True)\n",
    "workdir = Path(workdir)\n",
    "\n",
    "if is_train:\n",
    "    sample_submission_csv = os.path.join(data_dir, 'train_labels.csv')\n",
    "else:\n",
    "    sample_submission_csv = os.path.join(data_dir, 'sample_submission.csv')\n",
    "\n",
    "samples = {}\n",
    "competition_data = pd.read_csv(sample_submission_csv)\n",
    "for _, row in competition_data.iterrows():\n",
    "    # Note: For the test data, the \"scene\" column has no meaning, and the rotation_matrix and translation_vector columns are random.\n",
    "    if row.dataset not in samples:\n",
    "        samples[row.dataset] = []\n",
    "    samples[row.dataset].append(\n",
    "        Prediction(\n",
    "            image_id=None if is_train else row.image_id,\n",
    "            dataset=row.dataset,\n",
    "            filename=row.image\n",
    "        )\n",
    "    )\n",
    "\n",
    "for dataset in samples:\n",
    "    print(f'Dataset \"{dataset}\" -> num_images={len(samples[dataset])}')\n",
    "\n",
    "max_images = None  # Used For debugging only. Set to None to disable.\n",
    "datasets_to_process = None  # Not the best convention, but None means all datasets.\n",
    "\n",
    "if is_train:\n",
    "    # max_images = 5\n",
    "\n",
    "    # Note: When running on the training dataset, the notebook will hit the time limit and die. Use this filter to run on a few specific datasets.\n",
    "    datasets_to_process = [\n",
    "    \t# New data.\n",
    "    \t'amy_gardens',\n",
    "    \t'ETs',\n",
    "    \t'fbk_vineyard',\n",
    "    \t'stairs',\n",
    "    \t# Data from IMC 2023 and 2024.\n",
    "    \t'imc2024_dioscuri_baalshamin',\n",
    "    \t'imc2023_theather_imc2024_church',\n",
    "    \t'imc2023_heritage',\n",
    "    \t'imc2023_haiper',\n",
    "    \t'imc2024_lizard_pond',\n",
    "    \t# Crowdsourced PhotoTourism data.\n",
    "    \t'pt_stpeters_stpauls',\n",
    "    \t'pt_brandenburg_british_buckingham',\n",
    "    \t'pt_piazzasanmarco_grandplace',\n",
    "    \t'pt_sacrecoeur_trevi_tajmahal',\n",
    "    ]\n",
    "\n",
    "for dataset, predictions in samples.items():\n",
    "    if datasets_to_process and dataset not in datasets_to_process:\n",
    "        print(f'Skipping \"{dataset}\"')\n",
    "        continue\n",
    "    \n",
    "    images_dir = os.path.join(data_dir, 'train' if is_train else 'test', dataset)\n",
    "    if not os.path.exists(images_dir):\n",
    "        print(f'Images dir \"{images_dir}\" does not exist. Skipping \"{dataset}\"')\n",
    "        continue\n",
    "    \n",
    "    images_dir = Path(images_dir)\n",
    "\n",
    "    print(f'Images dir: {images_dir}')\n",
    "\n",
    "    image_names = [p.filename for p in predictions]\n",
    "    if max_images is not None:\n",
    "        image_names = image_names[:max_images]\n",
    "\n",
    "    print(f'\\nProcessing dataset \"{dataset}\": {len(image_names)} images')\n",
    "\n",
    "    filename_to_index = {p.filename: idx for idx, p in enumerate(predictions)}\n",
    "    \n",
    "    !rm -rf $workdir/$dataset\n",
    "\n",
    "    sfm_pairs = workdir / dataset / \"pairs-sfm.txt\"\n",
    "    loc_pairs = workdir / dataset / \"pairs-loc.txt\"\n",
    "    sfm_dir = workdir / dataset / \"sfm\"\n",
    "    features = workdir / dataset / \"features.h5\"\n",
    "    matches = workdir / dataset / \"matches.h5\"\n",
    "    topk_save_path = workdir / dataset / \"topk.json\"\n",
    "    topk_vis_path = workdir / dataset / \"show_topk\"\n",
    "    topk = 20\n",
    "\n",
    "    os.makedirs(topk_vis_path, exist_ok=True)\n",
    "\n",
    "    feature_conf = extract_features.confs[\"disk\"]\n",
    "    matcher_conf = match_features.confs[\"disk+lightglue\"]\n",
    "\n",
    "    if len(image_names) > 20 and len(image_names) < 60:\n",
    "        # disk lightglue topk\n",
    "        start = time.time()\n",
    "        extract_features.main(feature_conf, images_dir, image_list=image_names, feature_path=features)\n",
    "        pairs_from_exhaustive.main(sfm_pairs, image_list=image_names)\n",
    "        match_features.main(matcher_conf, sfm_pairs, features=features, matches=matches)\n",
    "\n",
    "        from utils import  parser_h5s, get_topk_candidates\n",
    "        res = parser_h5s(features, matches, sfm_pairs, min_match_score=0.2)\n",
    "        topks = get_topk_candidates(res, images_dir, topk_vis_path, k=topk, min_matches=15, vis=True)\n",
    "        with open(topk_save_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(topks, f, ensure_ascii=False, indent=4)\n",
    "    \n",
    "        end = time.time()\n",
    "        print(f'\\033[93BOQ TOPK time: { end - start} seconds\\033[0m')\n",
    "\n",
    "    \n",
    "    elif len(image_names) >= 60:\n",
    "        start = time.time()\n",
    "        topks = boq_sort_topk(images_dir, image_names, boq_model, device, k=topk, vis=True, vis_save_dir=topk_vis_path)\n",
    "        ##boq global topk\n",
    "        with open(topk_save_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(topks, f, ensure_ascii=False, indent=4)\n",
    "    \n",
    "        end = time.time()\n",
    "        print(\"\\033[91mDisk + light_glue + topk cost time: { end - start} seconds\\033[0m')\n",
    "\n",
    "    else:\n",
    "        # do not top k, just do masr3d\n",
    "\n",
    "        print('\\033[94mskip this dataset, cause number of imgs lower than 20\\033[0m')\n",
    "        pass\n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    gc.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
